INTRODUCTION
The Puzzling Puzzles of Harry Harlow and Edward Deci
In the middle of the last century, two young scientists conducted experiments that should have changed the world—but did not.
Harry F. Harlow was a professor of psychology at the University of Wisconsin who, in the 1940s, established one of the world’s first laboratories for studying primate behavior. One day in 1949, Harlow and two colleagues gathered eight rhesus monkeys for a two-week experiment on learning. The researchers devised a simple mechanical puzzle like the one pictured on the next page. Solving it required three steps: pull out the vertical pin, undo the hook, and lift the hinged cover. Pretty easy for you and me, far more challenging for a thirteen-pound lab monkey.

Harlow’s puzzle in the starting (left) and solved (right) positions.
The experimenters placed the puzzles in the monkeys’ cages to observe how they reacted—and to prepare them for tests of their problem-solving prowess at the end of the two weeks. But almost immediately, something strange happened. Unbidden by any outside urging and unprompted by the experimenters, the monkeys began playing with the puzzles with focus, determination, and what looked like enjoyment. And in short order, they began figuring out how the contraptions worked. By the time Harlow tested the monkeys on days 13 and 14 of the experiment, the primates had become quite adept. They solved the puzzles frequently and quickly; two-thirds of the time they cracked the code in less than sixty seconds.
Now, this was a bit odd. Nobody had taught the monkeys how to remove the pin, slide the hook, and open the cover. Nobody had rewarded them with food, affection, or even quiet applause when they succeeded. And that ran counter to the accepted notions of how primates—including the bigger-brained, less hairy primates known as human beings—behaved.
Scientists then knew that two main drives powered behavior. The first was the biological drive. Humans and other animals ate to sate their hunger, drank to quench their thirst, and copulated to satisfy their carnal urges. But that wasn’t happening here. “Solution did not lead to food, water, or sex gratification,” Harlow reported.1
But the only other known drive also failed to explain the monkeys’ peculiar behavior. If biological motivations came from within, this second drive came from without—the rewards and punishments the environment delivered for behaving in certain ways. This was certainly true for humans, who responded exquisitely to such external forces. If you promised to raise our pay, we’d work harder. If you held out the prospect of getting an A on the test, we’d study longer. If you threatened to dock us for showing up late or for incorrectly completing a form, we’d arrive on time and tick every box. But that didn’t account for the monkeys’ actions either. As Harlow wrote, and you can almost hear him scratching his head, “The behavior obtained in this investigation poses some interesting questions for motivation theory, since significant learning was attained and efficient performance maintained without resort to special or extrinsic incentives.”
What else could it be?
To answer the question, Harlow offered a novel theory—what amounted to a third drive: “The performance of the task,” he said, “provided intrinsic reward.” The monkeys solved the puzzles simply because they found it gratifying to solve puzzles. They enjoyed it. The joy of the task was its own reward.
If this notion was radical, what happened next only deepened the confusion and controversy. Perhaps this newly discovered drive—Harlow eventually called it “intrinsic motivation”—was real. But surely it was subordinate to the other two drives. If the monkeys were rewarded—with raisins!—for solving the puzzles, they’d no doubt perform even better. Yet when Harlow tested that approach, the monkeys actually made more errors and solved the puzzles less frequently. “Introduction of food in the present experiment,” Harlow wrote, “served to disrupt performance, a phenomenon not reported in the literature.”
Now, this was really odd. In scientific terms, it was akin to rolling a steel ball down an inclined plane to measure its velocity—only to watch the ball float into the air instead. It suggested that our understanding of the gravitational pulls on our behavior was inadequate—that what we thought were fixed laws had plenty of loopholes. Harlow emphasized the “strength and persistence” of the monkeys’ drive to complete the puzzles. Then he noted:
It would appear that this drive . . . may be as basic and strong as the [other] drives. Furthermore, there is some reason to believe that [it] can be as efficient in facilitating learning.2
At the time, however, the prevailing two drives held a tight grip on scientific thinking. So Harlow sounded the alarm. He urged scientists to “close down large sections of our theoretical junkyard” and offer fresher, more accurate accounts of human behavior.3 He warned that our explanation of why we did what we did was incomplete. He said that to truly understand the human condition, we had to take account of this third drive.
Then he pretty much dropped the whole idea.
Rather than battle the establishment and begin offering a more complete view of motivation, Harlow abandoned this contentious line of research and later became famous for studies on the science of affection.4 His notion of this third drive bounced around the psychological literature, but it remained on the periphery—of behavioral science and of our understanding of ourselves. It would be two decades before another scientist picked up the thread that Harlow had so provocatively left on that Wisconsin laboratory table.
In the summer of 1969, Edward Deci was a Carnegie Mellon University psychology graduate student in search of a dissertation topic. Deci, who had already earned an MBA from Wharton, was intrigued by motivation but suspected that scholars and businesspeople had misunderstood it. So, tearing a page from the Harlow playbook, he set out to study the topic with the help of a puzzle.
Deci chose the Soma puzzle cube, a then popular Parker Brothers offering that, thanks to YouTube, retains something of a cult following today. The puzzle, shown below, consists of seven plastic pieces—six comprising four one-inch cubes, one comprising three one-inch cubes. Players can assemble the seven pieces into a few million possible combinations—from abstract shapes to recognizable objects.

The seven pieces of the Soma puzzle unassembled (left) and then fashioned into one of several million possible configurations.
For the study, Deci divided participants, male and female university students, into an experimental group (what I’ll call Group A) and a control group (what I’ll call Group B). Each participated in three one-hour sessions held on consecutive days.
Here’s how the sessions worked: Each participant entered a room and sat at a table on top of which were the seven Soma puzzle pieces, drawings of three puzzle configurations, and copies of Time, The New Yorker, and Playboy. (Hey, it was 1969.) Deci sat on the opposite end of the table to explain the instructions and to time performance with a stopwatch.
In the first session, members of both groups had to assemble the Soma pieces to replicate the configurations before them. In the second session, they did the same thing with different drawings—only this time Deci told Group A that they’d be paid $1 (the equivalent of nearly $6 today) for every configuration they successfully reproduced. Group B, meanwhile, got new drawings but no pay. Finally, in the third session, both groups received new drawings and had to reproduce them for no compensation, just as in session one. (See the table below.)
HOW THE TWO GROUPS WERE TREATED

The twist came midway through each session. After a participant had assembled the Soma puzzle pieces to match two of the three drawings, Deci halted the proceedings. He said that he was going to give them a fourth drawing—but to choose the right one, he needed to feed their completion times into a computer. And—this being the late 1960s, when room-straddling mainframes were the norm and desktop PCs were still a decade away—that meant he had to leave for a little while.
On the way out, he said, “I shall be gone only a few minutes, you may do whatever you like while I’m gone.” But Deci wasn’t really plugging numbers into an ancient teletype. Instead, he walked to an adjoining room connected to the experiment room by a one-way window. Then, for exactly eight minutes, he watched what people did when left alone. Did they continue fiddling with the puzzle, perhaps attempting to reproduce the third drawing? Or did they do something else—page through the magazines, check out the centerfold, stare into space, catch a quick nap?
In the first session, not surprisingly, there wasn’t much difference between what the Group A and Group B participants did during that secretly watched eight-minute free-choice period. Both continued playing with the puzzle, on average, for between three and a half and four minutes, suggesting they found it at least somewhat interesting.
On the second day, during which Group A participants were paid for each successful configuration and Group B participants were not, the unpaid group behaved mostly as they had during the first free-choice period. But the paid group suddenly got really interested in Soma puzzles. On average, the people in Group A spent more than five minutes messing with the puzzle, perhaps getting a head start on that third challenge or gearing up for the chance to earn some beer money when Deci returned. This makes intuitive sense, right? It’s consistent with what we believe about motivation: Reward me and I’ll work harder.
Yet what happened on the third day confirmed Deci’s own suspicions about the peculiar workings of motivation—and gently called into question a guiding premise of modern life. This time, Deci told the participants in Group A that there was only enough money to pay them for one day and that this third session would therefore be unpaid. Then things unfolded just as before—two puzzles, followed by Deci’s interruption.
During the ensuing eight-minute free-choice period, the subjects in the never-been-paid Group B actually played with the puzzle for a little longer than they had in previous sessions. Maybe they were becoming ever more engaged; maybe it was just a statistical quirk. But the subjects in Group A, who previously had been paid, responded differently. They now spent significantly less time playing with the puzzle—not only about two minutes less than during their paid session, but about a full minute less than in the first session when they initially encountered, and obviously enjoyed, the puzzles.
In an echo of what Harlow discovered two decades earlier, Deci revealed that human motivation seemed to operate by laws that ran counter to what most scientists and citizens believed. From the office to the playing field, we knew what got people going. Rewards—especially cold, hard cash—intensified interest and enhanced performance. What Deci found, and then confirmed in two additional studies he conducted shortly thereafter, was almost the opposite. “When money is used as an external reward for some activity, the subjects lose intrinsic interest for the activity,” he wrote.5 Rewards can deliver a short-term boost—just as a jolt of caffeine can keep you cranking for a few more hours. But the effect wears off—and, worse, can reduce a person’s longer-term motivation to continue the project.
Human beings, Deci said, have an “inherent tendency to seek out novelty and challenges, to extend and exercise their capacities, to explore, and to learn.” But this third drive was more fragile than the other two; it needed the right environment to survive. “One who is interested in developing and enhancing intrinsic motivation in children, employees, students, etc., should not concentrate on external-control systems such as monetary rewards,” he wrote in a follow-up paper.6 Thus began what for Deci became a lifelong quest to rethink why we do what we do—a pursuit that sometimes put him at odds with fellow psychologists, got him fired from a business school, and challenged the operating assumptions of organizations everywhere.
“It was controversial,” Deci told me one spring morning forty years after the Soma experiments. “Nobody was expecting rewards would have a negative effect.”
 
 
THIS IS A BOOK about motivation. I will show that much of what we believe about the subject just isn’t so—and that the insights that Harlow and Deci began uncovering a few decades ago come much closer to the truth. The problem is that most businesses haven’t caught up to this new understanding of what motivates us. Too many organizations—not just companies, but governments and nonprofits as well—still operate from assumptions about human potential and individual performance that are outdated, unexamined, and rooted more in folklore than in science. They continue to pursue practices such as short-term incentive plans and pay-for-performance schemes in the face of mounting evidence that such measures usually don’t work and often do harm. Worse, these practices have infiltrated our schools, where we ply our future workforce with iPods, cash, and pizza coupons to “incentivize” them to learn. Something has gone wrong.
The good news is that the solution stands before us—in the work of a band of behavioral scientists who have carried on the pioneering efforts of Harlow and Deci and whose quiet work over the last half-century offers us a more dynamic view of human motivation. For too long, there’s been a mismatch between what science knows and what business does. The goal of this book is to repair that breach.
Drive has three parts. Part One will look at the flaws in our reward-and-punishment system and propose a new way to think about motivation. Chapter 1 will examine how the prevailing view of motivation is becoming incompatible with many aspects of contemporary business and life. Chapter 2 will reveal the seven reasons why carrot-and-stick extrinsic motivators often produce the opposite of what they set out to achieve. (Following that is a short addendum, Chapter 2a, that shows the special circumstances when carrots and sticks actually can be effective.) Chapter 3 will introduce what I call “Type I” behavior, a way of thinking and an approach to business grounded in the real science of human motivation and powered by our third drive—our innate need to direct our own lives, to learn and create new things, and to do better by ourselves and our world.
Part Two will examine the three elements of Type I behavior and show how individuals and organizations are using them to improve performance and deepen satisfaction. Chapter 4 will explore autonomy, our desire to be self-directed. Chapter 5 will look at mastery, our urge to make progress and get better at what we do. Chapter 6 will explore purpose, our yearning to contribute and to be part of something larger than ourselves.
Part Three, the Type I Toolkit, is a comprehensive set of resources to help you create settings in which Type I behavior can flourish. Here you’ll find everything from dozens of exercises to awaken motivation in yourself and others, to discussion questions for your book club, to a supershort summary of Drive that will help you fake your way through a cocktail party. And while this book is mostly about business, in this section I’ll offer some thoughts about how to apply these concepts to education and to our lives outside of work.
But before we get down to all that, let’s begin with a thought experiment, one that requires going back in time—to the days when John Major was Britain’s prime minister, Barack Obama was a skinny young law professor, Internet connections were dial-up, and a blackberry was still just a fruit.
 
Part One
A New Operating System
 
CHAPTER 1
The Rise and Fall of Motivation 2.0
Imagine it’s 1996. You sit down with an economist—an accomplished business school professor with a Ph.D. in economics. You say to her: “I’ve got a crystal ball here that can peer fifteen years into the future. I’d like to test your forecasting powers.”
She’s skeptical, but she decides to humor you.
“I’m going to describe two new encyclopedias—one just out, the other to be launched in a few years. You have to predict which will be more successful in 2011.”
“Bring it,” she says.
“The first encyclopedia comes from Microsoft. As you know, Microsoft is already a large and profitable company. And with last year’s introduction of Windows 95, it is becoming an era-defining colossus. Microsoft will fund this encyclopedia. It will pay professional writers and editors to craft articles on thousands of topics. Well-compensated managers will oversee the project to ensure it’s completed on budget and on time. Then Microsoft will sell the encyclopedia on CD-ROMs and later online.
“The second encyclopedia won’t come from a company. It will be created by tens of thousands of people who write and edit articles for fun. These hobbyists won’t need any special qualifications to participate. And nobody will be paid a dollar or a euro or a yen to write or edit articles. Participants will have to contribute their labor—sometimes twenty and thirty hours per week—for free. The encyclopedia itself, which will exist online, will also be free—no charge for anyone who wants to use it.
“Now,” you say to the economist, “think forward fifteen years. According to my crystal ball, in 2011, one of these encyclopedias will be the largest and most popular in the world and the other will be defunct. Which is which?”
In 1996, I doubt you could have found a single sober economist anywhere on planet Earth who would not have picked that first model as the success. Any other conclusion would have been laughable—contrary to nearly every business principle she taught her students. It would have been like asking a zoologist who would win a 200-meter footrace between a cheetah and your brother-in-law. Not even close.
Sure, that ragtag band of volunteers might produce something. But there was no way its product could compete with an offering from a powerful profit-driven company. The incentives were all wrong. Microsoft stood to gain from the success of its product; everyone involved in the other project knew from the outset that success would earn them nothing. Most important, Microsoft’s writers, editors, and managers were paid. The other project’s contributors were not. In fact, it probably cost them money each time they performed free work instead of remunerative labor. The question was such a no-brainer that our economist wouldn’t even have considered putting it on an exam for her MBA class. It was too easy.
But you know how things turned out.
On October 31, 2009, Microsoft pulled the plug on MSN Encarta, its disc and online encyclopedia, which had been on the market for sixteen years. Meanwhile, Wikipedia—that second model—ended up becoming the largest and most popular encyclopedia in the world. Just nine years after its inception, Wikipedia had more than 17 million articles in some 270 languages, including 3.5 million in English alone.1
What happened? The conventional view of human motivation has a very hard time explaining this result.
 
THE TRIUMPH OF CARROTS AND STICKS 
Computers—whether the giant mainframes in Deci’s experiments, the iMac on which I’m writing this sentence, or the mobile phone chirping in your pocket—all have operating systems. Beneath the surface of the hardware you touch and the programs you manipulate is a complex layer of software that contains the instructions, protocols, and suppositions that enable everything to function smoothly. Most of us don’t think much about operating systems. We notice them only when they start failing—when the hardware and software they’re supposed to manage grow too large and complicated for the current operating system to handle. Then our computer starts crashing. We complain. And smart software developers, who’ve always been tinkering with pieces of the program, sit down to write a fundamentally better one—an upgrade.
Societies also have operating systems. The laws, social customs, and economic arrangements that we encounter each day sit atop a layer of instructions, protocols, and suppositions about how the world works. And much of our societal operating system consists of a set of assumptions about human behavior.
In our very early days—I mean very early days, say, fifty thousand years ago—the underlying assumption about human behavior was simple and true. We were trying to survive. From roaming the savannah to gather food to scrambling for the bushes when a saber-toothed tiger approached, that drive guided most of our behavior. Call this early operating system Motivation 1.0. It wasn’t especially elegant, nor was it much different from those of rhesus monkeys, giant apes, or many other animals. But it served us nicely. It worked well. Until it didn’t.
As humans formed more complex societies, bumping up against strangers and needing to cooperate in order to get things done, an operating system based purely on the biological drive was inadequate. In fact, sometimes we needed ways to restrain this drive—to prevent me from swiping your dinner and you from stealing my spouse. And so in a feat of remarkable cultural engineering, we slowly replaced the existing version with one more compatible with how we’d now begun working and living.
At the core of this new and improved operating system was a revised and more accurate assumption: Humans are more than the sum of our biological urges. That first drive still mattered—no doubt about that—but it didn’t fully account for who we are. We also had a second drive—to seek reward and avoid punishment more broadly. And it was from this insight that a new operating system—call it Motivation 2.0—arose. (Of course, other animals also respond to rewards and punishments, but only humans have proved able to channel this drive to develop everything from contract law to convenience stores.)
Harnessing this second drive has been essential to economic progress around the world, especially during the last two centuries. Consider the Industrial Revolution. Technological developments—steam engines, railroads, widespread electricity—played a crucial role in fostering the growth of industry. But so did less tangible innovations—in particular, the work of an American engineer named Frederick Winslow Taylor. In the early 1900s, Taylor, who believed businesses were being run in an inefficient, haphazard way, developed what he called “scientific management.” His invention was a form of “software” expertly crafted to run atop the Motivation 2.0 platform. And it was widely and quickly adopted.
Workers, this approach held, were like parts in a complicated machine. If they did the right work in the right way at the right time, the machine would function smoothly. And to ensure that happened, you simply rewarded the behavior you sought and punished the behavior you discouraged. People would respond rationally to these external forces—these extrinsic motivators—and both they and the system itself would flourish. We tend to think that coal and oil have powered economic development. But in some sense, the engine of commerce has been fueled equally by carrots and sticks.
The Motivation 2.0 operating system has endured for a very long time. Indeed, it is so deeply embedded in our lives that most of us scarcely recognize that it exists. For as long as any of us can remember, we’ve configured our organizations and constructed our lives around its bedrock assumption: The way to improve performance, increase productivity, and encourage excellence is to reward the good and punish the bad.
Despite its greater sophistication and higher aspirations, Motivation 2.0 still wasn’t exactly ennobling. It suggested that, in the end, human beings aren’t much different from livestock—that the way to get us moving in the right direction is by dangling a crunchier carrot or wielding a sharper stick. But what this operating system lacked in enlightenment, it made up for in effectiveness. It worked well—extremely well. Until it didn’t.
As the twentieth century progressed, as economies grew still more complex, and as the people in them had to deploy new, more sophisticated skills, the Motivation 2.0 approach encountered some resistance. In the 1950s, Abraham Maslow, a former student of Harry Harlow’s at the University of Wisconsin, developed the field of humanistic psychology, which questioned the belief that human behavior was purely the ratlike seeking of positive stimuli and avoidance of negative stimuli. In 1960, MIT management professor Douglas McGregor imported some of Maslow’s ideas to the business world. McGregor challenged the presumption that humans are fundamentally inert—that absent external rewards and punishments, we wouldn’t do much. People have other, higher drives, he said. And these drives could benefit businesses if managers and business leaders respected them.
In the same era, and in a similar spirit, Frederick Herzberg, a psychologist-turned-management professor, proposed that two key factors determined how people fared on the job. The first were “hygiene” factors—extrinsic rewards such as pay, working conditions, and job security. Their absence created dissatisfaction, but their presence didn’t lead to job satisfaction. The second were “motivators”—things like enjoyment of the work itself, genuine achievement, and personal growth. These internal desires were what really boosted both satisfaction and performance and were where managers ought to focus their attention. Meanwhile, W. Edwards Deming, whose work was embraced in Japan with the same ferocity with which it was ignored in the U.S., argued that the route to quality and continual improvement was intrinsic motivation rather than extrinsic motivators like bonuses, incentive plans, and forced rankings. Thanks in part to McGregor, Herzberg, and Deming, companies evolved a bit. Dress codes relaxed, schedules became more flexible. Many organizations looked for ways to grant employees greater autonomy and to help them grow. These refinements repaired some weaknesses, but they amounted to a modest improvement rather than a thorough upgrade—Motivation 2.1.
And so this general approach remained intact—because it was, after all, easy to understand, simple to monitor, and straightforward to enforce. But in the first ten years of this century—a period of truly staggering underachievement in business, technology, and social progress—we’ve discovered that this sturdy, old operating system doesn’t work nearly as well. It crashes—often and unpredictably. It forces people to devise workarounds to bypass its flaws. Most of all, it is proving incompatible with many aspects of contemporary business. And if we examine those incompatibility problems closely, we’ll realize that modest updates—a patch here or there—will not solve the problem. What we need is a full-scale upgrade.
 
THREE INCOMPATIBILITY PROBLEMS 
Motivation 2.0 still serves some purposes well. It’s just deeply unreliable. Sometimes it works; many times it doesn’t. And understanding its defects will help determine which parts to keep and which to discard as we fashion an upgrade. The glitches fall into three broad categories. Our current operating system has become far less compatible with, and at times downright antagonistic to: how we organize what we do; how we think about what we do; and how we do what we do.
 How We Organize What We Do 
Go back to that encyclopedic showdown between Microsoft and Wikipedia. The assumptions at the heart of Motivation 2.0 suggest that such a result shouldn’t even be possible. Wikipedia’s triumph seems to defy the laws of behavioral physics.
Now, if this all-volunteer, all-amateur encyclopedia were the only instance of its kind, we might dismiss it as an aberration, an exception that proves the rule. But it’s not. Instead, Wikipedia represents the most powerful new business model of the twenty-first century: open source.
Fire up your home computer, for example. When you visit the Web to check the weather forecast or order some sneakers, you might be using Firefox, a free open-source Web browser created almost exclusively by volunteers around the world. Unpaid laborers who give away their product? That couldn’t be sustainable. The incentives are all wrong. Yet Firefox now has more than 350 million users.
Or walk into the IT department of a large company anywhere in the world and ask for a tour. That company’s corporate computer servers could well run on Linux, software devised by an army of unpaid programmers and available for free. Linux now powers one in four corporate servers. Then ask an employee to explain how the company’s website works. Humming beneath the site is probably Apache, free open-source Web server software created and maintained by a far-flung global group of volunteers. Apache’s share of the corporate Web server market: 52 percent. In other words, companies that typically rely on external rewards to manage their employees run some of their most important systems with products created by nonemployees who don’t seem to need such rewards.
And it’s not just the tens of thousands of software projects across the globe. Today you can find: open-source cookbooks; open-source textbooks; open-source car design; open-source medical research; open-source legal briefs; open-source stock photography; open-source prosthetics; open-source credit unions; open-source cola; and for those for whom soft drinks won’t suffice, open-source beer.
This new way of organizing what we do doesn’t banish extrinsic rewards. People in the open-source movement haven’t taken vows of poverty. For many, participation in these projects can burnish their reputations and sharpen their skills, which can enhance their earning power. Entrepreneurs have launched new, and sometimes lucrative, companies to help organizations implement and maintain open-source software applications.
But ultimately, open source depends on intrinsic motivation with the same ferocity that older business models rely on extrinsic motivation, as several scholars have shown. MIT management professor Karim Lakhani and Boston Consulting Group consultant Bob Wolf surveyed 684 open-source developers, mostly in North America and Europe, about why they participated in these projects. Lakhani and Wolf uncovered a range of motives, but they found “that enjoyment-based intrinsic motivation, namely how creative a person feels when working on the project, is the strongest and most pervasive driver.”2 A large majority of programmers, the researchers discovered, reported that they frequently reached the state of optimal challenge called “flow.” Likewise, three German economists who studied open-source projects around the world found that what drives participants is “a set of predominantly intrinsic motives”—in particular, “the fun . . . of mastering the challenge of a given software problem” and the “desire to give a gift to the programmer community.”3 Motivation 2.0 has little room for these sorts of impulses.
What’s more, open source is only one way people are restructuring what they do along new organizational lines and atop different motivational ground. Let’s move from software code to the legal code. The laws in most developed countries permit essentially two types of business organizations—profit and nonprofit. One makes money, the other does good. And the most prominent member of that first category is the publicly held corporation—owned by shareholders and run by managers who are overseen by a board of directors. The managers and directors bear one overriding responsibility: to maximize shareholder gain. Other types of business organizations steer by the same rules of the road. In the United States, for instance, partnerships, S corporations, C corporations, limited liability companies, and other business configurations all aim toward a common end. The objective of those who run them—practically, legally, in some ways morally—is to maximize profit.
Let me give a rousing, heartfelt, and grateful cheer for these business forms and the farsighted countries that enable their citizens to create them. Without them, our lives would be infinitely less prosperous, less healthy, and less happy. But in the last few years, several people around the world have been changing the recipe and cooking up new varieties of business organizations.
For example, in April 2008, Vermont became the first U.S. state to allow a new type of business called the “low-profit limited liability company.” Dubbed an L3C, this entity is a corporation—but not as we typically think of it. As one report explained, an L3C “operate[s] like a for-profit business generating at least modest profits, but its primary aim [is] to offer significant social benefits.” Three other U.S. states have followed Vermont’s lead.4 An L3C in North Carolina, for instance, is buying abandoned furniture factories in the state, updating them with green technology, and leasing them back to beleaguered furniture manufacturers at a low rate. The venture hopes to make money, but its real purpose is to help revitalize a struggling region.
Meanwhile, Nobel Peace Prize winner Muhammad Yunus has begun creating what he calls “social businesses.” These are companies that raise capital, develop products, and sell them in an open market but do so in the service of a larger social mission—or as he puts it, “with the profit-maximization principle replaced by the social-benefit principle.” The Fourth Sector Network in the United States and Denmark is promoting “the for-benefit organization”—a hybrid that it says represents a new category of organization that is both economically self-sustaining and animated by a public purpose. One example: Mozilla, the entity that gave us Firefox, is organized as a “for-benefit” organization. And three U.S. entrepreneurs have invented the “B Corporation,” a designation that requires companies to amend their bylaws so that the incentives favor long-term value and social impact instead of short-term economic gain.5
Neither open-source production nor previously unimagined “not only for profit” businesses are yet the norm, of course. And they won’t consign the public corporation to the trash heap. But their emergence tells us something important about where we’re heading. “There’s a big movement out there that is not yet recognized as a movement,” a lawyer who specializes in for-benefit organizations told The New York Times.6 One reason could be that traditional businesses are profit maximizers, which square perfectly with Motivation 2.0. These new entities are purpose maximizers—which are unsuited to this older operating system because they flout its very principles.
 How We Think About What We Do 
When I took my first economics course back in the early 1980s, our professor—a brilliant lecturer with a Patton-like stage presence—offered an important clarification before she’d chalked her first indifference curve on the blackboard. Economics, she explained, wasn’t the study of money. It was the study of behavior. In the course of a day, each of us was constantly figuring the cost and benefits of our actions and then deciding how to act. Economists studied what people did, rather than what we said, because we did what was best for us. We were rational calculators of our economic self-interest.
When I studied law a few years later, a similar idea reappeared. The newly ascendant field of “law and economics” held that precisely because we were such awesome self-interest calculators, laws and regulations often impeded, rather than permitted, sensible and just outcomes. I survived law school in no small part because I discovered the talismanic phrase and offered it on exams: “In a world of perfect information and low transaction costs, the parties will bargain to a wealth-maximizing result.”
Then, about a decade later, came a curious turn of events that made me question much of what I’d worked hard, and taken on enormous debt, to learn. In 2002, the Nobel Foundation awarded its prize in economics to a guy who wasn’t even an economist. And they gave him the field’s highest honor largely for revealing that we weren’t always rational calculators of our economic self-interest and that the parties often didn’t bargain to a wealth-maximizing result. Daniel Kahneman, an American psychologist who won the Nobel Prize in economics that year for work he’d done with Israeli Amos Tversky, helped force a change in how we think about what we do. And one of the implications of this new way of thinking is that it calls into question many of the assumptions of Motivation 2.0.
Kahneman and others in the field of behavioral economics agreed with my professor that economics was the study of human economic behavior. They just believed that we’d placed too much emphasis on the economic and not enough on the human. That hyperrational calculator-brained person wasn’t real. He was a convenient fiction.
Play a game with me and I’ll try to illustrate the point. Suppose somebody gives me ten dollars and tells me to share it—some, all, or none—with you. If you accept my offer, we both get to keep the money. If you reject it, neither of us gets anything. If I offered you six dollars (keeping four for myself), would you take it? Almost certainly. If I offered you five, you’d probably take that, too. But what if I offered you two dollars? Would you take it? In an experiment replicated around the world, most people rejected offers of two dollars and below.7 That makes no sense in terms of wealth maximization. If you take my offer of two dollars, you’re two dollars richer. If you reject it, you get nothing. Your cognitive calculator knows two is greater than zero—but because you’re a human being, your notions of fair play or your desire for revenge or your simple irritation overrides it.
In real life our behavior is far more complex than the textbook allows and often confounds the idea that we’re purely rational. We don’t save enough for retirement even though it’s to our clear economic advantage to do so. We hang on to bad investments longer than we should, because we feel far sharper pain from losing money than we do from gaining the exact same amount. Give us a choice of two television sets, we’ll pick one; toss in an irrelevant third choice, and we’ll pick the other. In short, we are irrational—and predictably so, says economist Dan Ariely, author of Predictably Irrational, a book that offers an entertaining and engaging overview of behavioral economics.
The trouble for our purposes is that Motivation 2.0 assumes we’re the same robotic wealth-maximizers I was taught we were a couple of decades ago. Indeed, the very premise of extrinsic incentives is that we’ll always respond rationally to them. But even most economists don’t believe that anymore. Sometimes these motivators work. Often they don’t. And many times, they inflict collateral damage. In short, the new way economists think about what we do is hard to reconcile with Motivation 2.0.
What’s more, if people do things for lunk-headed, backward-looking reasons, why wouldn’t we also do things for significance-seeking, self-actualizing reasons? If we’re predictably irrational—and we clearly are—why couldn’t we also be predictably transcendent?
If that seems far-fetched, consider some of our other bizarre behaviors. We leave lucrative jobs to take low-paying ones that provide a clearer sense of purpose. We work to master the clarinet on weekends although we have little hope of making a dime (Motivation 2.0) or acquiring a mate (Motivation 1.0) from doing so. We play with puzzles even when we don’t get a few raisins or dollars for solving them.
Some scholars are already widening the reach of behavioral economics to encompass these ideas. The most prominent is Bruno Frey, an economist at the University of Zurich. Like the behavioral economists, he has argued that we need to move beyond the idea of Homo Oeconomicus (Economic Man, that fictional wealth-maximizing android). But his extension goes in a slightly different direction—to what he calls Homo Oeconomicus Maturus (or Mature Economic Man). This figure, he says, “is more ‘mature’ in the sense that he is endowed with a more refined motivational structure.” In other words, to fully understand human economic behavior, we have to come to terms with an idea at odds with Motivation 2.0. As Frey writes, “Intrinsic motivation is of great importance for all economic activities. It is inconceivable that people are motivated solely or even mainly by external incentives.”8
 How We Do What We Do 
If you manage other people, take a quick glance over your shoulder. There’s a ghost hovering there. His name is Frederick Winslow Taylor—remember him from earlier in the chapter?—and he’s whispering in your ear. “Work,” Taylor is murmuring, “consists mainly of simple, not particularly interesting, tasks. The only way to get people to do them is to incentivize them properly and monitor them carefully.” In the early 1900s, Taylor had a point. Today, in much of the world, that’s less true. Yes, for some people work remains routine, unchallenging, and directed by others. But for a surprisingly large number of people, jobs have become more complex, more interesting, and more self-directed. And that type of work presents a direct challenge to the assumptions of Motivation 2.0.
Begin with complexity. Behavioral scientists often divide what we do on the job or learn in school into two categories: “algorithmic” and “heuristic.” An algorithmic task is one in which you follow a set of established instructions down a single pathway to one conclusion. That is, there’s an algorithm for solving it. A heuristic task is the opposite. Precisely because no algorithm exists for it, you have to experiment with possibilities and devise a novel solution. Working as a grocery checkout clerk is mostly algorithmic. You do pretty much the same thing over and over in a certain way. Creating an ad campaign is mostly heuristic. You have to come up with something new. 
During the twentieth century, most work was algorithmic—and not just jobs where you turned the same screw the same way all day long. Even when we traded blue collars for white, the tasks we carried out were often routine. That is, we could reduce much of what we did—in accounting, law, computer programming, and other fields—to a script, a spec sheet, a formula, or a series of steps that produced a right answer. But today, in much of North America, Western Europe, Japan, South Korea, and Australia, routine white-collar work is disappearing. It’s racing offshore to wherever it can be done the cheapest. In India, Bulgaria, the Philippines, and other countries, lower-paid workers essentially run the algorithm, figure out the correct answer, and deliver it instantaneously from their computer to someone six thousand miles away.
But offshoring is just one pressure on rule-based, left-brain work. Just as oxen and then forklifts replaced simple physical labor, computers are replacing simple intellectual labor. So while outsourcing is just beginning to pick up speed, software can already perform many rule-based, professional functions better, more quickly, and more cheaply than we can. That means that your cousin the CPA, if he’s doing mostly routine work, faces competition not just from five-hundred-dollar-a-month accountants in Manila, but from tax preparation programs anyone can download for thirty dollars. The consulting firm McKinsey & Co. estimates that in the United States, only 30 percent of job growth now comes from algorithmic work, while 70 percent comes from heuristic work.9 A key reason: Routine work can be outsourced or automated; artistic, empathic, nonroutine work generally cannot.10
The implications for motivation are vast. Researchers such as Harvard Business School’s Teresa Amabile have found that external rewards and punishments—both carrots and sticks—can work nicely for algorithmic tasks. But they can be devastating for heuristic ones. Those sorts of challenges—solving novel problems or creating something the world didn’t know it was missing—depend heavily on Harlow’s third drive. Amabile calls it the intrinsic motivation principle of creativity, which holds, in part: “Intrinsic motivation is conducive to creativity; controlling extrinsic motivation is detrimental to creativity.”11 In other words, the central tenets of Motivation 2.0 may actually impair performance of the heuristic, right-brain work on which modern economies depend.
Partly because work has become more creative and less routine, it has also become more enjoyable. That, too, scrambles Motivation 2.0’s assumptions. This operating system rests on the belief that work is not inherently enjoyable—which is precisely why we must coax people with external rewards and threaten them with outside punishment. One unexpected finding of the psychologist Mihaly Csikszentmihalyi, whom we’ll encounter in Chapter 5, is that people are much more likely to report having “optimal experiences” on the job than during leisure. But if work is inherently enjoyable for more and more people, then the external inducements at the heart of Motivation 2.0 become less necessary. Worse, as Deci began discovering forty years ago, adding certain kinds of extrinsic rewards on top of inherently interesting tasks can often dampen motivation and diminish performance.
Once again, certain bedrock notions suddenly seem less sturdy. Take the curious example of Vocation Vacations. This is a business in which people pay their hard-earned money . . . to work at another job. They use their vacation time to test-drive being a chef, running a bike shop, or operating an animal shelter. The emergence of this and similar ventures suggests that work, which economists have always considered a “disutility” (something we’d avoid unless we received a payment in return), can often be a “utility” (something we’d pursue even in the absence of a tangible return).
Finally, because work is supposed to be dreary, Motivation 2.0 holds that people need to be carefully monitored so they don’t shirk. This idea, too, is becoming less relevant and, in many ways, less possible. Consider, for instance, that America alone now has more than 18 million of what the U.S. Census Bureau calls “non-employer businesses”—businesses without any paid employees. Since people in these businesses don’t have any underlings, they don’t have anybody to manage or motivate. But since they don’t have bosses themselves, there’s nobody to manage or motivate them. They have to be self-directed.
So do people who aren’t technically working for themselves. In the United States, 33.7 million people telecommute at least one day a month, and 14.7 million do so every day—placing a substantial portion of the workforce beyond the gaze of a manager, forcing them to direct their own work.12 And even if many organizations haven’t opted for measures like these, they’re generally becoming leaner and less hierarchical. In an effort to reduce costs, they trim the fatty middle. That means managers oversee larger numbers of people and therefore scrutinize each one less closely.
As organizations flatten, companies need people who are self-motivated. That forces many organizations to become more like open source projects. Nobody “manages” the open source contributors. Nobody sits around trying to figure out how to “motivate” them. That’s why Linux and Wikipedia and Firefox work. Routine, not-so-interesting jobs require direction; nonroutine, more interesting work depends on self-direction. One business leader, who didn’t want to be identified, said it plainly. When he conducts job interviews, he tells prospective employees: “If you need me to motivate you, I probably don’t want to hire you.”
TO RECAP, Motivation 2.0 suffers from three compatibility problems. It doesn’t mesh with the way many new business models are organizing what we do—because we’re intrinsically motivated purpose maximizers, not only extrinsically motivated profit maximizers. It doesn’t comport with the way that twenty-first-century economics thinks about what we do—because economists are finally realizing that we’re full-fledged human beings, not single-minded economic robots. And perhaps most important, it’s hard to reconcile with much of what we actually do at work—because for growing numbers of people, work is often creative, interesting, and self-directed rather than unrelentingly routine, boring, and other-directed. Taken together, these compatibility problems warn us that something’s gone awry in our motivational operating system.
But in order to figure out exactly what, and as an essential step in fashioning a new one, we need to take a look at the bugs themselves.
 
CHAPTER 2
Seven Reasons Carrots and Sticks (Often) Don’t Work . . .
An object in motion will stay in motion, and an object at rest will stay at rest, unless acted on by an outside force.
That’s Newton’s first law of motion. Like Newton’s other laws, this one is elegant and simple—which is part of its power. Even people like me, who bumbled through high school physics, can understand it and can use it to interpret the world.
Motivation 2.0 is similar. At its heart are two elegant and simple ideas:
Rewarding an activity will get you more of it. Punishing an activity will get you less of it.
And just as Newton’s principles can help us explain our physical environment or chart the path of a thrown ball, Motivation 2.0’s principles can help us comprehend our social surroundings and predict the trajectory of human behavior.
But Newtonian physics runs into problems at the subatomic level. Down there—in the land of hadrons, quarks, and Schrödinger’s cat—things get freaky. The cool rationality of Isaac Newton gives way to the bizarre unpredictability of Lewis Carroll. Motivation 2.0 is similar in this regard, too. When rewards and punishments encounter our third drive, something akin to behavioral quantum mechanics seems to take over and strange things begin to happen.
Of course, the starting point for any discussion of motivation in the workplace is a simple fact of life: People have to earn a living. Salary, contract payments, some benefits, a few perks are what I call “baseline rewards.” If someone’s baseline rewards aren’t adequate or equitable, her focus will be on the unfairness of her situation and the anxiety of her circumstance. You’ll get neither the predictability of extrinsic motivation nor the weirdness of intrinsic motivation. You’ll get very little motivation at all. The best use of money as a motivator is to pay people enough to take the issue of money off the table.
But once we’ve cleared the table, carrots and sticks can achieve precisely the opposite of their intended aims. Mechanisms designed to increase motivation can dampen it. Tactics aimed at boosting creativity can reduce it. Programs to promote good deeds can make them disappear. Meanwhile, instead of restraining negative behavior, rewards and punishments can often set it loose—and give rise to cheating, addiction, and dangerously myopic thinking.
This is weird. And it doesn’t hold in all circumstances (about which more after this chapter). But as Edward Deci’s Soma puzzle experiment demonstrates, many practices whose effectiveness we take for granted produce counterintuitive results: They can give us less of what we want—and more of what we don’t want. These are the bugs in Motivation 2.0. And they rise to the surface whether we’re promising rupees in India, charging shekels in Israel, drawing blood in Sweden, or painting portraits in Chicago.
 
LESS OF WHAT WE WANT 
One of the most enduring scenes in American literature offers an important lesson in human motivation. In Chapter 2 of Mark Twain’s The Adventures of Tom Sawyer, Tom faces the dreary task of whitewashing Aunt Polly’s 810-square-foot fence. He’s not exactly thrilled with the assignment. “Life to him seemed hollow, and existence but a burden,” Twain writes.
But just when Tom has nearly lost hope, “nothing less than a great, magnificent inspiration” bursts upon him. When his friend Ben ambles by and mocks Tom for his sorry lot, Tom acts confused. Slapping paint on a fence isn’t a grim chore, he says. It’s a fantastic privilege—a source of, ahem, intrinsic motivation. The job is so captivating that when Ben asks to try a few brushstrokes himself, Tom refuses. He doesn’t relent until Ben gives up his apple in exchange for the opportunity.
Soon more boys arrive, all of whom tumble into Tom’s trap and end up whitewashing the fence—several times over—on his behalf. From this episode, Twain extracts a key motivational principle, namely “that Work consists of whatever a body is OBLIGED to do, and that Play consists of whatever a body is not obliged to do.” He goes on to write:
There are wealthy gentlemen in England who drive four-horse passenger-coaches twenty or thirty miles on a daily line, in the summer, because the privilege costs them considerable money; but if they were offered wages for the service, that would turn it into work and then they would resign.1
		 
In other words, rewards can perform a weird sort of behavioral alchemy: They can transform an interesting task into a drudge. They can turn play into work. And by diminishing intrinsic motivation, they can send performance, creativity, and even upstanding behavior toppling like dominoes. Let’s call this the Sawyer Effect.a A sampling of intriguing experiments around the world reveals the four realms where this effect kicks in.
 Intrinsic Motivation 
Behavioral scientists like Deci began discovering the Sawyer Effect nearly forty years ago, although they didn’t use that term. Instead, they referred to the counterintuitive consequences of extrinsic incentives as “the hidden costs of rewards.” That, in fact, was the title of the first book on the subject—a 1978 research volume that was edited by psychologists Mark Lepper and David Greene.
One of Lepper and Greene’s early studies (which they carried out with a third colleague, Robert Nisbett) has become a classic in the field and among the most cited articles in the motivation literature. The three researchers watched a classroom of preschoolers for several days and identified the children who chose to spend their “free play” time drawing. Then they fashioned an experiment to test the effect of rewarding an activity these children clearly enjoyed.
The researchers divided the children into three groups. The first was the “expected-award” group. They showed each of these children a “Good Player” certificate—adorned with a blue ribbon and featuring the child’s name—and asked if the child wanted to draw in order to receive the award. The second group was the “unexpected-award” group. Researchers asked these children simply if they wanted to draw. If they decided to, when the session ended, the researchers handed each child one of the “Good Player” certificates. The third group was the “no-award” group. Researchers asked these children if they wanted to draw, but neither promised them a certificate at the beginning nor gave them one at the end.
Two weeks later, back in the classroom, teachers set out paper and markers during the preschool’s free play period while the researchers secretly observed the students. Children previously in the “unexpected-award” and “no-award” groups drew just as much, and with the same relish, as they had before the experiment. But children in the first group—the ones who’d expected and then received an award—showed much less interest and spent much less time drawing. 2 The Sawyer Effect had taken hold. Even two weeks later, those alluring prizes—so common in classrooms and cubicles—had turned play into work.
To be clear, it wasn’t necessarily the rewards themselves that dampened the children’s interest. Remember: When children didn’t expect a reward, receiving one had little impact on their intrinsic motivation. Only contingent rewards—if you do this, then you’ll get that—had the negative effect. Why? “If-then” rewards require people to forfeit some of their autonomy. Like the gentlemen driving carriages for money instead of fun, they’re no longer fully controlling their lives. And that can spring a hole in the bottom of their motivational bucket, draining an activity of its enjoyment.
Lepper and Greene replicated these results in several subsequent experiments with children. As time went on, other researchers found similar results with adults. Over and over again, they discovered that extrinsic rewards—in particular, contingent, expected, “if-then” rewards—snuffed out the third drive.
These insights proved so controversial—after all, they called into question a standard practice of most companies and schools—that in 1999 Deci and two colleagues reanalyzed nearly three decades of studies on the subject to confirm the findings. “Careful consideration of reward effects reported in 128 experiments lead to the conclusion that tangible rewards tend to have a substantially negative effect on intrinsic motivation,” they determined. “When institutions—families, schools, businesses, and athletic teams, for example—focus on the short-term and opt for controlling people’s behavior,” they do considerable long-term damage.3
Try to encourage a kid to learn math by paying her for each workbook page she completes—and she’ll almost certainly become more diligent in the short term and lose interest in math in the long term. Take an industrial designer who loves his work and try to get him to do better by making his pay contingent on a hit product—and he’ll almost certainly work like a maniac in the short term, but become less interested in his job in the long term. As one leading behavioral science textbook puts it, “People use rewards expecting to gain the benefit of increasing another person’s motivation and behavior, but in so doing, they often incur the unintentional and hidden cost of undermining that person’s intrinsic motivation toward the activity.”4
This is one of the most robust findings in social science—and also one of the most ignored. Despite the work of a few skilled and passionate popularizers—in particular, Alfie Kohn, whose prescient 1993 book, Punished by Rewards, lays out a devastating indictment of extrinsic incentives—we persist in trying to motivate people this way. Perhaps we’re scared to let go of Motivation 2.0, despite its obvious downsides. Perhaps we can’t get our minds around the peculiar quantum mechanics of intrinsic motivation.
Or perhaps there’s a better reason. Even if those controlling “if-then” rewards activate the Sawyer Effect and suffocate the third drive, maybe they actually get people to perform better. If that’s the case, perhaps they’re not so bad. So let’s ask: Do extrinsic rewards boost performance? Four economists went to India to find out.
 High Performance 
One of the difficulties of laboratory experiments that test the impact of extrinsic motivators like cash is the cost. If you’re going to pay people to perform, you have to pay them a meaningful amount. And in the United States or Europe, where standards of living are high, an individually meaningful amount multiplied by dozens of participants can rack up unsustainably large bills for behavioral scientists.
In part to circumvent this problem, a quartet of economists—including Dan Ariely, whom I mentioned in the last chapter—set up shop in Madurai, India, to gauge the effects of extrinsic incentives on performance. Because the cost of living in rural India is much lower than in North America, the researchers could offer large rewards without breaking their own banks.
They recruited eighty-seven participants and asked them to play several games—for example, tossing tennis balls at a target, unscrambling anagrams, recalling a string of digits—that required motor skills, creativity, or concentration. To test the power of incentives, the experimenters offered three types of rewards for reaching certain performance levels.
One-third of the participants could earn a small reward—4 rupees (at the time equal to about a day’s pay in Madurai) for reaching their performance targets. One-third could earn a medium reward—40 rupees (about two weeks’ pay). And one-third could earn a very large reward—400 rupees (nearly five months’ pay).
What happened? Did the size of the reward predict the quality of the performance?
Yes. But not in the way you might expect. As it turned out, the people offered the medium-sized bonus didn’t perform any better than those offered the small one. And those in the 400-rupee superincentivized group? They fared worst of all. By nearly every measure, they lagged behind both the low-reward and medium-reward participants. Reporting the results for the Federal Reserve Bank of Boston, the researchers wrote, “In eight of the nine tasks we examined across the three experiments, higher incentives led to worse performance.”5
Let’s circle back to this conclusion for a moment. Four economists—two from MIT, one from Carnegie Mellon, and one from the University of Chicago—undertake research for the Federal Reserve System, one of the most powerful economic actors in the world. But instead of affirming a simple business principle—higher rewards lead to higher performance—they seem to refute it. And it’s not just American researchers reaching these counterintuitive conclusions. In 2009, scholars at the London School of Economics—alma mater of eleven Nobel laureates in economics—analyzed fifty-one studies of corporate pay-for-performance plans. These economists’ conclusion: “We find that financial incentives . . . can result in a negative impact on overall performance.”6 On both sides of the Atlantic, the gap between what science is learning and what business is doing is wide.
“Many existing institutions provide very large incentives for exactly the type of tasks we used here,” Ariely and his colleagues wrote. “Our results challenge [that] assumption. Our experiment suggests . . . that one cannot assume that introducing or raising incentives always improves performance.” Indeed, in many instances, contingent incentives—that cornerstone of how businesses attempt to motivate employees—may be “a losing proposition.”
Of course, procrastinating writers notwithstanding, few of us spend our working hours flinging tennis balls or doing anagrams. How about the more creative tasks that are more akin to what we actually do on the job?
 Creativity 
For a quick test of problem-solving prowess, few exercises are more useful than the “candle problem.” Devised by psychologist Karl Duncker in the 1930s, the candle problem is used in a wide variety of experiments in behavioral science. Follow along and see how you do.
You sit at a table next to a wooden wall and the experimenter gives you the materials shown below: a candle, some tacks, and a book of matches.

The candle problem presented.
Your job is to fix the candle to the wall so that the wax doesn’t drip on the table. Think for a moment about how you’d solve the problem. Many people begin by trying to tack the candle to the wall. But that doesn’t work. Some light a match, melt the side of the candle, and try to adhere it to the wall. That doesn’t work either. But after five or ten minutes, most people stumble onto the solution, which you can see below.

The candle problem solved.
The key is to overcome what’s called “functional fixedness.” You look at the box and see only one function—as a container for the tacks. But by thinking afresh, you eventually see that the box can have another function—as a platform for the candle. To reprise language from the previous chapter, the solution isn’t algorithmic (following a set path) but heuristic (breaking from the path to discover a novel strategy).
What happens when you give people a conceptual challenge like this and offer them rewards for speedy solutions? Sam Glucksberg, a psychologist now at Princeton University, tested this in the early 1960s by timing how quickly two groups of participants solved the candle problem. He told the first group that he was timing their work merely to establish norms for how long it typically took someone to complete this sort of puzzle. To the second group he offered incentives. If a participant’s time was among the fastest 25 percent of all the people being tested, that participant would receive $5. If the participant’s time was the fastest of all, the reward would be $20. Adjusted for inflation, those are decent sums of money for a few minutes of effort—a nice motivator.
How much faster did the incentivized group come up with a solution? On average, it took them nearly three and a half minutes longer.7 Yes, three and a half minutes longer. (Whenever I’ve relayed these results to a group of businesspeople, the reaction is almost always a loud, pained, involuntary gasp.) In direct contravention to the core tenets of Motivation 2.0, an incentive designed to clarify thinking and sharpen creativity ended up clouding thinking and dulling creativity. Why? Rewards, by their very nature, narrow our focus. That’s helpful when there’s a clear path to a solution. They help us stare ahead and race faster. But “if-then” motivators are terrible for challenges like the candle problem. As this experiment shows, the rewards narrowed people’s focus and blinkered the wide view that might have allowed them to see new uses for old objects.
Something similar seems to occur for challenges that aren’t so much about cracking an existing problem but about iterating something new. Teresa Amabile, the Harvard Business School professor and one of the world’s leading researchers on creativity, has frequently tested the effects of contingent rewards on the creative process. In one study, she and two colleagues recruited twenty-three professional artists from the United States who had produced both commissioned and noncommissioned artwork. They asked the artists to randomly select ten commissioned works and ten noncommissioned works. Then Amabile and her team gave the works to a panel of accomplished artists and curators, who knew nothing about the study, and asked the experts to rate the pieces on creativity and technical skill.
“Our results were quite startling,” the researchers wrote. “The commissioned works were rated as significantly less creative than the non-commissioned works, yet they were not rated as different in technical quality. Moreover, the artists reported feeling significantly more constrained when doing commissioned works than when doing non-commissioned works.” One artist whom they interviewed describes the Sawyer Effect in action:
Not always, but a lot of the time, when you are doing a piece for someone else it becomes more “work” than joy. When I work for myself there is the pure joy of creating and I can work through the night and not even know it. On a commissioned piece you have to check yourself—be careful to do what the client wants.8
Another study of artists over a longer period shows that a concern for outside rewards might actually hinder eventual success. In the early 1960s, researchers surveyed sophomores and juniors at the School of the Art Institute of Chicago about their attitudes toward work and whether they were more intrinsically or extrinsically motivated. Using these data as a benchmark, another researcher followed up with these students in the early 1980s to see how their careers were progressing. Among the starkest findings, especially for men: “The less evidence of extrinsic motivation during art school, the more success in professional art both several years after graduation and nearly twenty years later.” Painters and sculptors who were intrinsically motivated, those for whom the joy of discovery and the challenge of creation were their own rewards, were able to weather the tough times—and the lack of remuneration and recognition—that inevitably accompany artistic careers. And that led to yet another paradox in the Alice in Wonderland world of the third drive. “Those artists who pursued their painting and sculpture more for the pleasure of the activity itself than for extrinsic rewards have produced art that has been socially recognized as superior,” the study said. “It is those who are least motivated to pursue extrinsic rewards who eventually receive them.”9
The principle holds for scientists as well. In one 2009 study, MIT’s Pierre Azoulay and his colleagues compared two different ways to incentivize creativity in the sciences. They examined scientists who received grants from the U.S. National Institutes of Health (NIH), which emphasizes external controls such as “short review cycles, pre-defined deliverables, and renewal policies unforgiving of failure.” Then they looked at scientists at the Howard Hughes Medical Institute (HHMI), whose funding process “tolerates early failure, rewards long-term success, and gives its appointees great freedom to experiment.” The result? HHMI investigators produced high-impact papers at a much higher rate than their similarly accomplished NIH counterparts.
Amabile and others have found that extrinsic rewards can be effective for algorithmic tasks—those that depend on following an existing formula to its logical conclusion. But for more right-brain undertakings—those that demand flexible problem-solving, inventiveness, or conceptual understanding—contingent rewards can be dangerous. Rewarded subjects often have a harder time seeing the periphery and crafting original solutions. This, too, is one of the sturdiest findings in social science—especially as Amabile and others have refined it over the years.10 For artists, scientists, inventors, schoolchildren, and the rest of us, intrinsic motivation—the drive to do something because it is interesting, challenging, and absorbing—is essential for high levels of creativity. But the “if-then” motivators that are the staple of most businesses often stifle, rather than stir, creative thinking. As the economy moves toward more right-brain, conceptual work—as more of us deal with our own versions of the candle problem—this might be the most alarming gap between what science knows and what business does.
 Good Behavior 
Philosophers and medical professionals have long debated whether blood donors should be paid. Some claim that blood, like human tissue or organs, is special—that we shouldn’t be able to buy and sell it like a barrel of crude oil or a crate of ball bearings. Others argue that we should shelve our squeamishness, because paying for this substance will ensure an ample supply.
But in 1970, British sociologist Richard Titmuss, who had studied blood donation in the United Kingdom, offered a bolder speculation. Paying for blood wasn’t just immoral, he said. It was also inefficient. If Britain decided to pay citizens to donate, that would actually reduce the country’s blood supply. It was an oddball notion, to be sure. Economists snickered. And Titmuss never tested the idea; it was merely a philosophical hunch.11
But a quarter-century later, two Swedish economists decided to see if Titmuss was right. In an intriguing field experiment, they visited a regional blood center in Gothenburg and found 153 women who were interested in giving blood. Then—as seems to be the custom among motivation researchers—they divided the women into three groups.12 Experimenters told those in the first group that blood donation was voluntary. These participants could give blood, but they wouldn’t receive a payment. The experimenters offered the second group a different arrangement. If these participants gave blood, they’d each receive 50 Swedish kronor (about $7). The third group received a variation on that second offer: a 50-kronor payment with an immediate option to donate the amount to a children’s cancer charity.
Of the first group, 52 percent of the women decided to go ahead and donate blood. They were altruistic citizens apparently, willing to do a good deed for their fellow Swedes even in the absence of compensation.
And the second group? Motivation 2.0 would suggest that this group might be a bit more motivated to donate. They’d shown up, which indicated intrinsic motivation. Getting a few kronor on top might give that impulse a boost. But—as you might have guessed by now—that’s not what happened. In this group, only 30 percent of the women decided to give blood. Instead of increasing the number of blood donors, offering to pay people decreased the number by nearly half.
Meanwhile, the third group—which had the option of donating the fee directly to charity—responded much the same as the first group. Fifty-three percent became blood donors.b
Titmuss’s hunch might have been right, after all. Adding a monetary incentive didn’t lead to more of the desired behavior. It led to less. The reason: It tainted an altruistic act and “crowded out” the intrinsic desire to do something good.13 Doing good is what blood donation is all about. It provides what the American Red Cross brochures say is “a feeling that money can’t buy.” That’s why voluntary blood donations invariably increase during natural disasters and other calamities.14 But if governments were to pay people to help their neighbors during these crises, donations might decline.
That said, in the Swedish example, the reward itself wasn’t inherently destructive. The immediate option to donate the 50-kronor payment rather than pocket it seemed to negate the effect. This, too, is extremely important. It’s not that all rewards at all times are bad. For instance, when the Italian government gave blood donors paid time off work, donations increased.15 The law removed an obstacle to altruism. So while a few advocates would have you believe in the basic evil of extrinsic incentives, that’s just not empirically true. What is true is that mixing rewards with inherently interesting, creative, or noble tasks—deploying them without understanding the peculiar science of motivation—is a very dangerous game. When used in these situations, “if-then” rewards usually do more harm than good. By neglecting the ingredients of genuine motivation—autonomy, mastery, and purpose—they limit what each of us can achieve.
 
MORE OF WHAT WE DON’T WANT 
In the upside-down universe of the third drive, rewards can often produce less of the very things they’re trying to encourage. But that’s not the end of the story. When used improperly, extrinsic motivators can have another unintended collateral consequence: They can give us more of what we don’t want. Here, again, what business does hasn’t caught up with what science knows. And what science is revealing is that carrots and sticks can promote bad behavior, create addiction, and encourage short-term thinking at the expense of the long view.
 Unethical Behavior 
What could be more valuable than having a goal? From our earliest days, teachers, coaches, and parents advise us to set goals and to work mightily to achieve them—and with good reason. Goals work. The academic literature shows that by helping us tune out distractions, goals can get us to try harder, work longer, and achieve more.
But recently a group of scholars from the Harvard Business School, Northwestern University’s Kellogg School of Management, the University of Arizona’s Eller College of Management, and the University of Pennsylvania’s Wharton School questioned the efficacy of this broad prescription. “Rather than being offered as an ‘over-the-counter’ salve for boosting performance, goal setting should be prescribed selectively, presented with a warning label, and closely monitored,” they wrote.16 Goals that people set for themselves and that are devoted to attaining mastery are usually healthy. But goals imposed by others—sales targets, quarterly returns, standardized test scores, and so on—can sometimes have dangerous side effects.
Like all extrinsic motivators, goals narrow our focus. That’s one reason they can be effective; they concentrate the mind. But as we’ve seen, a narrowed focus exacts a cost. For complex or conceptual tasks, offering a reward can blinker the wide-ranging thinking necessary to come up with an innovative solution. Likewise, when an extrinsic goal is paramount—particularly a short-term, measurable one whose achievement delivers a big payoff—its presence can restrict our view of the broader dimensions of our behavior. As the cadre of business school professors write, “Substantial evidence demonstrates that in addition to motivating constructive effort, goal setting can induce unethical behavior.”
The examples are legion, the researchers note. Sears imposes a sales quota on its auto repair staff—and workers respond by overcharging customers and completing unnecessary repairs. Enron sets lofty revenue goals—and the race to meet them by any means possible catalyzes the company’s collapse. Ford is so intent on producing a certain car at a certain weight at a certain price by a certain date that it omits safety checks and unleashes the dangerous Ford Pinto.
The problem with making an extrinsic reward the only destination that matters is that some people will choose the quickest route there, even if it means taking the low road.
Indeed, most of the scandals and misbehavior that have seemed endemic to modern life involve shortcuts. Executives game their quarterly earnings so they can snag a performance bonus. Secondary school counselors doctor student transcripts so their seniors can get into college.17 Athletes inject themselves with steroids to post better numbers and trigger lucrative performance bonuses.
Contrast that approach with behavior sparked by intrinsic motivation. When the reward is the activity itself—deepening learning, delighting customers, doing one’s best—there are no shortcuts. The only route to the destination is the high road. In some sense, it’s impossible to act unethically because the person who’s disadvantaged isn’t a competitor but yourself.
Of course, all goals are not created equal. And—let me emphasize this point—goals and extrinsic rewards aren’t inherently corrupting. But goals are more toxic than Motivation 2.0 recognizes. In fact, the business school professors suggest they should come with their own warning label: “Goals may cause systematic problems for organizations due to narrowed focus, unethical behavior, increased risk taking, decreased cooperation, and decreased intrinsic motivation. Use care when applying goals in your organization.”
If carrots-as-goals sometimes encourage unworthy behavior, then sticks-as-punishment should be able to halt it, right? Not so fast. The third drive is less mechanistic and more surprising than that, as two Israeli economists discovered at some day care centers.
In 2000, economists Uri Gneezy and Aldo Rustichini studied a group of child care facilities in Haifa, Israel, for twenty weeks.18 The centers opened at 7:30 A.M. and closed at 4:00 P.M. Parents had to retrieve their children by the closing time or a teacher would have to stay late.
During the first four weeks of the experiment, the economists recorded how many parents arrived late each week. Then, before the fifth week, with the permission of the day care centers, they posted the following sign:
ANNOUNCEMENT: FINE FOR COMING LATE
As you all know, the official closing time of the day care center is 1600 every day. Since some parents have been coming late, we (with the approval of the Authority for Private Day-Care Centers in Israel) have decided to impose a fine on parents who come late to pick up their children.
As of next Sunday a fine of NS 10c will be charged every time a child is collected after 1610. This fine will be calculated monthly, it is to be paid together with the regular monthly payment.
Sincerely,
The manager of the day-care center
The theory underlying the fine, said Gneezy and Rustichini, was straightforward: “When negative consequences are imposed on a behavior, they will produce a reduction of that particular response.” In other words, thwack the parents with a fine, and they’ll stop showing up late.
But that’s not what happened. “After the introduction of the fine we observed a steady increase in the number of parents coming late,” the economists wrote. “The rate finally settled, at a level that was higher, and almost twice as large as the initial one.”19 And in language reminiscent of Harry Harlow’s head scratching, they write that the existing literature didn’t account for such a result. Indeed, the “possibility of an increase in the behavior being punished was not even considered.”
Up pops another bug in Motivation 2.0. One reason most parents showed up on time is that they had a relationship with the teachers—who, after all, were caring for their precious sons and daughters—and wanted to treat them fairly. Parents had an intrinsic desire to be scrupulous about punctuality. But the threat of a fine—like the promise of the kronor in the blood experiment—edged aside that third drive. The fine shifted the parents’ decision from a partly moral obligation (be fair to my kids’ teachers) to a pure transaction (I can buy extra time). There wasn’t room for both. The punishment didn’t promote good behavior; it crowded it out.
Addiction 
If some scientists believe that “if-then” motivators and other extrinsic rewards resemble prescription drugs that carry potentially dangerous side effects, others believe they’re more like illegal drugs that foster a deeper and more pernicious dependency. According to these scholars, cash rewards and shiny trophies can provide a delicious jolt of pleasure at first, but the feeling soon dissipates—and to keep it alive, the recipient requires ever larger and more frequent doses.
The Russian economist Anton Suvorov has constructed an elaborate econometric model to demonstrate this effect, configured around what’s called “principal-agent theory.” Think of the principal as the motivator—the employer, the teacher, the parent. Think of the agent as the motivatee—the employee, the student, the child. A principal essentially tries to get the agent to do what the principal wants, while the agent balances his own interests with whatever the principal is offering. Using a blizzard of complicated equations that test a variety of scenarios between principal and agent, Suvorov has reached conclusions that make intuitive sense to any parent who’s tried to get her kids to empty the garbage.
By offering a reward, a principal signals to the agent that the task is undesirable. (If the task were desirable, the agent wouldn’t need a prod.) But that initial signal, and the reward that goes with it, forces the principal onto a path that’s difficult to leave. Offer too small a reward and the agent won’t comply. But offer a reward that’s enticing enough to get the agent to act the first time, and the principal “is doomed to give it again in the second.” There’s no going back. Pay your son to take out the trash—and you’ve pretty much guaranteed the kid will never do it again for free. What’s more, once the initial money buzz tapers off, you’ll likely have to increase the payment to continue compliance.
As Suvorov explains, “Rewards are addictive in that once offered, a contingent reward makes an agent expect it whenever a similar task is faced, which in turn compels the principal to use rewards over and over again.” And before long, the existing reward may no longer suffice. It will quickly feel less like a bonus and more like the status quo—which then forces the principal to offer larger rewards to achieve the same effect.20
This addictive pattern is not merely blackboard theory. Brian Knutson, then a neuroscientist at the National Institute on Alcohol Abuse and Alcoholism, demonstrated as much in an experiment using the brain scanning technique known as functional magnetic resonance imaging (fMRI). He placed healthy volunteers into a giant scanner to watch how their brains responded during a game that involved the prospect of either winning or losing money. When participants knew they had a chance to win cash, activation occurred in the part of the brain called the nucleus accumbens. That is, when the participants anticipated getting a reward (but not when they anticipated losing one), a burst of the brain chemical dopamine surged to this part of the brain. Knutson, who is now at Stanford University, has found similar results in subsequent studies where people anticipated rewards. What makes this response interesting for our purposes is that the same basic physiological process—this particular brain chemical surging to this particular part of the brain—is what happens in addiction. The mechanism of most addictive drugs is to send a fusillade of dopamine to the nucleus accumbens. The feeling delights, then dissipates, then demands another dose. In other words, if we watch how people’s brains respond, promising them monetary rewards and giving them cocaine, nicotine, or amphetamines look disturbingly similar.21 This could be one reason that paying people to stop smoking often works in the short run. It replaces one (dangerous) addiction with another (more benign) one.
Rewards’ addictive qualities can also distort decision-making. Knutson has found that activation in the nucleus accumbens seems to predict “both risky choices and risk-seeking mistakes.” Get people fired up with the prospect of rewards, and instead of making better decisions, as Motivation 2.0 hopes, they can actually make worse ones. As Knutson writes, “This may explain why casinos surround their guests with reward cues (e.g., inexpensive food, free liquor, surprise gifts, potential jackpot prizes)—anticipation of rewards activates the [nucleus accumbens], which may lead to an increase in the likelihood of individuals switching from risk-averse to risk-seeking behavior.”22
In short, while that dangled carrot isn’t all bad in all circumstances, in some instances it operates similar to a rock of crack cocaine and can induce behavior similar to that found around the craps table or roulette wheel—not exactly what we hope to achieve when we “motivate” our teammates and coworkers.
 Short-Term Thinking 
Think back to the candle problem again. The incentivized participants performed worse than their counterparts because they were so focused on the prize that they failed to glimpse a novel solution on the periphery. Rewards, we’ve seen, can limit the breadth of our thinking. But extrinsic motivators—especially tangible, “if-then” ones—can also reduce the depth of our thinking. They can focus our sights on only what’s immediately before us rather than what’s off in the distance.
Many times a concentrated focus makes sense. If your office building is on fire, you want to find an exit immediately rather than ponder how to rewrite the zoning regulations. But in less dramatic circumstances, fixating on an immediate reward can damage performance over time. Indeed, what our earlier examples—unethical actions and addictive behavior—have in common, perhaps more than anything else, is that they’re entirely short-term. Addicts want the quick fix regardless of the eventual harm. Cheaters want the quick win—regardless of the lasting consequences.
Yet even when the behavior doesn’t devolve into shortcuts or addiction, the near-term allure of rewards can be harmful in the long run. Consider publicly held companies. Many such companies have existed for decades and hope to exist for decades more. But much of what their executives and middle managers do each day is aimed single-mindedly at the corporation’s performance over the next three months. At these companies, quarterly earnings are an obsession. Executives devote substantial resources to making sure the earnings come out just right. And they spend considerable time and brainpower offering guidance to stock analysts so that the market knows what to expect and therefore responds favorably. This laser focus on a narrow, near-term slice of corporate performance is understandable. It’s a rational response to stock markets that reward or punish tiny blips in those numbers, which, in turn, affect executives’ compensation.
But companies pay a steep price for not extending their gaze beyond the next quarter. Several researchers have found that companies that spend the most time offering guidance on quarterly earnings deliver significantly lower long-term growth rates than companies that offer guidance less frequently. (One reason: The earnings-obsessed companies typically invest less in research and development.)23 They successfully achieve their short-term goals, but threaten the health of the company two or three years hence. As the scholars who warned about goals gone wild put it, “The very presence of goals may lead employees to focus myopically on short-term gains and to lose sight of the potential devastating long-term effects on the organization.”24
Perhaps nowhere is this clearer than in the economic calamity that gripped the world economy in 2008 and 2009. Each player in the system focused only on the short-term reward—the buyer who wanted a house, the mortgage broker who wanted a commission, the Wall Street trader who wanted new securities to sell, the politician who wanted a buoyant economy during reelection—and ignored the long-term effects of their actions on themselves or others. When the music stopped, the entire system nearly collapsed. This is the nature of economic bubbles: What seems to be irrational exuberance is ultimately a bad case of extrinsically motivated myopia.
By contrast, the elements of genuine motivation that we’ll explore later, by their very nature, defy a short-term view. Take mastery. The objective itself is inherently long-term because complete mastery, in a sense, is unattainable. Even Roger Federer, for instance, will never fully “master” the game of tennis. But introducing an “if-then” reward to help develop mastery usually backfires. That’s why schoolchildren who are paid to solve problems typically choose easier problems and therefore learn less.25 The short-term prize crowds out the long-term learning.
In environments where extrinsic rewards are most salient, many people work only to the point that triggers the reward—and no further. So if students get a prize for reading three books, many won’t pick up a fourth, let alone embark on a lifetime of reading—just as executives who hit their quarterly numbers often won’t boost earnings a penny more, let alone contemplate the long-term health of their company. Likewise, several studies show that paying people to exercise, stop smoking, or take their medicines produces terrific results at first—but the healthy behavior disappears once the incentives are removed. However, when contingent rewards aren’t involved, or when incentives are used with the proper deftness, performance improves and understanding deepens. Greatness and nearsightedness are incompatible. Meaningful achievement depends on lifting one’s sights and pushing toward the horizon.
CARROTS AND STICKS: The Seven Deadly Flaws
	1. They can extinguish intrinsic motivation.
	2. They can diminish performance.
	3. They can crush creativity.
	4. They can crowd out good behavior.
	5. They can encourage cheating, shortcuts, and unethical behavior.
	6. They can become addictive.
	7. They can foster short-term thinking.